{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "7.4.1.gpt2_finetune_novel_LM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLpGW7Uj1GHG"
      },
      "source": [
        "# KoGPT-2를 활용한 한국어 언어 생성 모델 및 fine-tuning\n",
        "\n",
        "- 출처: <텐서플로2와 머신러닝으로 시작하는 자연어처리> 7장 실습코드\n",
        "- github: https://github.com/NLP-kr/tensorflow-ml-nlp-tf2-colab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5KbCCSrIGN8"
      },
      "source": [
        "## 환경 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnX9aMYLIGN-"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/requirements.txt -O requirements.txt\n",
        "!pip install -r requirements.txt\n",
        "!pip install tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlbXfSoaIGN_"
      },
      "source": [
        "## 데이터 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUzt2TBHIGN_"
      },
      "source": [
        "!mkdir -p data_in/KOR\n",
        "!wget https://raw.githubusercontent.com/NLP-kr/tensorflow-ml-nlp-tf2/master/7.PRETRAIN_METHOD/data_in/KOR/finetune_data.txt \\\n",
        "              -O data_in/KOR/finetune_data.txt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G25IgF_1ubQO"
      },
      "source": [
        "## 사전 학습 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz6czmk-IGOA"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import gluonnlp as nlp\n",
        "from gluonnlp.data import SentencepieceTokenizer\n",
        "from transformers import TFGPT2LMHeadModel\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9bWnNvsA_sF"
      },
      "source": [
        "GPT2Model\n",
        "\n",
        "- **_ init _** : TFGPT2LMHeadModel을 생성해서 실행할 수 있게 구현, transformer 생성 방식에 따라 모델 소스가 저장된 디렉토리 경로 입력\n",
        "- **call**: 출력 값은 tuple -> (last_hidden_states, past, hidden_status, attentions)\n",
        "    * **last_hidden_states**: 모델의 마지막 레이어에서 출력한 값\n",
        "    * **past**: 각 레이어에서 연산한 결과값 출력 -> 다음 토큰 예측시 연산 속도 빠르게 함. (입력한 시퀀스의 결괏값이 이미 있어서 이전 토큰에 대한 연산을 할 필요가 없기 때문)\n",
        "    * **hidden_states**: 전체 레이어에 대한 은닉 상태 벡터를 모두 출력한 값\n",
        "    * **attention**: 모든 레이어에 연산한 어텐션 맵 값\n",
        "- 생성 모델에 활용하기 위해서는 vocabulary에 대한 logit 값만 활용하도록 첫 번째 값인 last_hidden_states를 출력 -> self.gpt2(inputs)[0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "balBsaW8IGOB"
      },
      "source": [
        "class GPT2Model(tf.keras.Model):\n",
        "    def __init__(self, dir_path):\n",
        "        super(GPT2Model, self).__init__()\n",
        "        self.gpt2 = TFGPT2LMHeadModel.from_pretrained(dir_path)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        return self.gpt2(inputs)[0]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-M43bMFCmQX"
      },
      "source": [
        "## 사전 학습 모델 문장 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP8CyZPaIGOB"
      },
      "source": [
        "# 학습된 파라미터 다운 받기\n",
        "!wget https://www.dropbox.com/s/nzfa9xpzm4edp6o/gpt_ckpt.zip -O gpt_ckpt.zip\n",
        "!unzip -o gpt_ckpt.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJc8mSb2IGOB"
      },
      "source": [
        "BASE_MODEL_PATH = './gpt_ckpt'\n",
        "gpt_model = GPT2Model(BASE_MODEL_PATH) # BASE_MODEL_PATH 경로의 학습된 파라미터를 가지는 GPT-2 모델 선언\n",
        "\n",
        "# 제가 여러 가지 데이터셋으로 실험해보느라..\n",
        "# exo_model = GPT2Model(BASE_MODEL_PATH)\n",
        "# sunny_model = GPT2Model(BASE_MODEL_PATH)\n",
        "# novel_model = GPT2Model(BASE_MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sdx2t6WIGOC"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 10\n",
        "MAX_LEN = 30\n",
        "\n",
        "# tokenizer\n",
        "TOKENIZER_PATH = './gpt_ckpt/gpt2_kor_tokenizer.spiece'\n",
        "tokenizer = SentencepieceTokenizer(TOKENIZER_PATH)\n",
        "\n",
        "# 단어 사전\n",
        "vocab = nlp.vocab.BERTVocab.from_sentencepiece(TOKENIZER_PATH,\n",
        "                                               mask_token=None,\n",
        "                                               sep_token=None,\n",
        "                                               cls_token=None,\n",
        "                                               unknown_token='<unk>',\n",
        "                                               padding_token='<pad>',\n",
        "                                               bos_token='<s>',\n",
        "                                               eos_token='</s>')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X67Z9bi8v2hI"
      },
      "source": [
        "|스페셜 토큰|역할|\n",
        "|:-|:-|\n",
        "|< unk >|모르는 단어에 대한 토큰|\n",
        "|< pad >|배치 데이터 길이 맞추는 용도|\n",
        "|< s >|문장의 시작을 알림|\n",
        "|< /s >|문장의 종결을 알림|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4HEaMAf0dKj"
      },
      "source": [
        "def generate_sent(seed_word, model, max_step=100, greedy=False, top_k=0, top_p=0.):\n",
        "    sent = seed_word\n",
        "    toked = tokenizer(sent)\n",
        "    \n",
        "    for _ in range(max_step):\n",
        "        input_ids = tf.constant([vocab[vocab.bos_token],]  + vocab[toked])[None, :] \n",
        "        outputs = model(input_ids)[:, -1, :]\n",
        "        if greedy:\n",
        "            gen = vocab.to_tokens(tf.argmax(outputs, axis=-1).numpy().tolist()[0])\n",
        "        else:\n",
        "            output_logit = tf_top_k_top_p_filtering(outputs[0], top_k=top_k, top_p=top_p)\n",
        "            gen = vocab.to_tokens(tf.random.categorical(output_logit, 1).numpy().tolist()[0])[0]\n",
        "        if gen == '</s>':\n",
        "            break\n",
        "        sent += gen.replace('▁', ' ')\n",
        "        toked = tokenizer(sent)\n",
        "\n",
        "    return sent"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzstkcvUIGOC"
      },
      "source": [
        "def tf_top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-99999):\n",
        "    _logits = logits.numpy()\n",
        "    top_k = min(top_k, logits.shape[-1])  \n",
        "    if top_k > 0:\n",
        "        indices_to_remove = logits < tf.math.top_k(logits, top_k)[0][..., -1, None]\n",
        "        _logits[indices_to_remove] = filter_value\n",
        "\n",
        "    if top_p > 0.0:\n",
        "        sorted_logits = tf.sort(logits, direction='DESCENDING')\n",
        "        sorted_indices = tf.argsort(logits, direction='DESCENDING')\n",
        "        cumulative_probs = tf.math.cumsum(tf.nn.softmax(sorted_logits, axis=-1), axis=-1)\n",
        "\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "        sorted_indices_to_remove = tf.concat([[False], sorted_indices_to_remove[..., :-1]], axis=0)\n",
        "        indices_to_remove = sorted_indices[sorted_indices_to_remove].numpy().tolist()\n",
        "        \n",
        "        _logits[indices_to_remove] = filter_value\n",
        "    return tf.constant([_logits])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "jeSOcen8IGOC",
        "outputId": "7167eb41-1dc4-4e15-f9ac-da4eac533150"
      },
      "source": [
        "generate_sent('우리', gpt_model, greedy=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'우리 모두는 그 어느 때보다 더 많은 것을 얻어야 한다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "BpUimMRiIGOD",
        "outputId": "69a3b543-ca3e-445b-cb18-499fcb18d6dd"
      },
      "source": [
        "generate_sent('우리', gpt_model, top_k=0, top_p=0.95)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'우리보다 훨씬 여유있고 현명한 나였지만 동시에 우리 세대에 큰 영향을 미쳤던 자 그들에 대한 예의에 관해 생각해보면 어떨까, 하는 생각을 해본 적이 있다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Erl9ELSR0go4"
      },
      "source": [
        "## Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi0SDTfAIGOD"
      },
      "source": [
        "DATA_IN_PATH = './data_in/KOR/'\n",
        "TRAIN_DATA_FILE = 'finetune_data.txt'\n",
        "\n",
        "sents = [s[:-1] for s in open(DATA_IN_PATH + TRAIN_DATA_FILE).readlines()]"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjU0czU1IGOE"
      },
      "source": [
        "input_data = []\n",
        "output_data = []\n",
        "\n",
        "# 텍스트 데이터 토큰화 과정\n",
        "for s in sents:\n",
        "    tokens = [vocab[vocab.bos_token],]  + vocab[tokenizer(s)] + [vocab[vocab.eos_token],]\n",
        "    input_data.append(tokens[:-1])\n",
        "    output_data.append(tokens[1:])\n",
        "\n",
        "input_data = pad_sequences(input_data, MAX_LEN, value=vocab[vocab.padding_token])\n",
        "output_data = pad_sequences(output_data, MAX_LEN, value=vocab[vocab.padding_token])\n",
        "\n",
        "input_data = np.array(input_data, dtype=np.int64)\n",
        "output_data = np.array(output_data, dtype=np.int64)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Cy0tWm2IGOE"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, vocab[vocab.padding_token]))\n",
        "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
        "    pred *= mask    \n",
        "    acc = train_accuracy(real, pred)\n",
        "\n",
        "    return tf.reduce_mean(acc)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arB0-kuCIGOE"
      },
      "source": [
        "novel_model.compile(loss=loss_function,\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=[accuracy_function])"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov1IHbiWIGOE"
      },
      "source": [
        "history = novel_model.fit(input_data, output_data, \n",
        "                    batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxPeiFxjIGOF",
        "outputId": "c3dfef09-2455-44ec-d91e-277b1be62976"
      },
      "source": [
        "DATA_OUT_PATH = './data_out'\n",
        "model_name = \"tf2_gpt2_finetuned_model_novel\"\n",
        "\n",
        "save_path = os.path.join(DATA_OUT_PATH, model_name)\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "novel_model.gpt2.save_pretrained(save_path)\n",
        "\n",
        "loaded_gpt_model = GPT2Model(save_path)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the model checkpoint at ./data_out/tf2_gpt2_finetuned_model_novel.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BYZwUGmmk1U",
        "outputId": "09b265d6-cc0d-4ad9-c2a5-a360092228ec"
      },
      "source": [
        "# 저장된 모델 불러오기\n",
        "# 이 코드는 필요할 때 사용하세요!\n",
        "\n",
        "model_name = \"model folder\"\n",
        "model_path = os.path.join(DATA_OUT_PATH, model_name)\n",
        "model_model = GPT2Model(model_path)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the model checkpoint at ./data_out/tf2_gpt2_finetuned_model_exo.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTOM3vYPaai5"
      },
      "source": [
        "def gpt_fine_tuning_test(word, k=0, p=0):\n",
        "  print('GPT-2')\n",
        "  print('greedy True: ', generate_sent(word, gpt_model, greedy=True))\n",
        "  print('greedy False: ', generate_sent(word, gpt_model, top_k=k, top_p=p))\n",
        "  print()\n",
        "  print('EXO lyrics fine-tuning')\n",
        "  print('greedy True: ', generate_sent(word, exo_model, greedy=True))\n",
        "  print('greedy False: ', generate_sent(word, exo_model, top_k=k, top_p=p))\n",
        "  print()\n",
        "  print('Movie Sunny fine-tuning')\n",
        "  print('greedy True: ', generate_sent(word, sunny_model, greedy=True))\n",
        "  print('greedy False: ', generate_sent(word, sunny_model, top_k=k, top_p=p))\n",
        "  print()\n",
        "  print('Novel fine-tuning')\n",
        "  print('greedy True: ', generate_sent(word, novel_model, greedy=True))\n",
        "  print('greedy False: ', generate_sent(word, novel_model, top_k=k, top_p=p))"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcyoTWN8bZBt",
        "outputId": "b0cdb5c8-3f7b-4529-d020-8129428b56ae"
      },
      "source": [
        "gpt_fine_tuning_test('사랑', p=0.95)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPT-2\n",
            "greedy True:  사랑합니다\n",
            "greedy False:  사랑합니다 어서 오세요\n",
            "\n",
            "EXO lyrics fine-tuning\n",
            "greedy True:  사랑해요 마마마마마마마마마마마마마마마마마마마마마마마마마마마마마마마마마마마마마마마 Turn back\n",
            "greedy False:  사랑해요 마마! 내 꺼야\n",
            "\n",
            "Movie Sunny fine-tuning\n",
            "greedy True:  사랑 가득하고 즐거운\n",
            "greedy False:  사랑한다면 나이가 들수록 자연스럽게 늙는 법이지. 나이가 들수록 자연스럽게 늙는 법이지. 어<unk>히. 인생은 짧고 혁명은                                                                        \n",
            "\n",
            "Novel fine-tuning\n",
            "greedy True:  사랑한다면\n",
            "greedy False:  사랑해요 내 말 들을 형편이 안 되는 내 맘 알아요 속상해도 이해해 줄 거야\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBNamZ2Fbdas",
        "outputId": "1af99003-b9b5-41ac-f9d4-4c14096e2805"
      },
      "source": [
        "gpt_fine_tuning_test('인간', p=0.95)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPT-2\n",
            "greedy True:  인간관계에서 가장 중요한 것은 인간관계에서 가장 중요한 것이 인간관계라는 것을 잊지 말아야 한다.\n",
            "greedy False:  인간으로서의 기본 예의가 전혀 없는 것이다.\n",
            "\n",
            "EXO lyrics fine-tuning\n",
            "greedy True:  인간에게 있어서 가장 아름다운 이별은 무엇일까?\n",
            "greedy False:  인간 사냥꾼은 없다\"고 말한 뒤, 무언가 잃어버린 듯한 기분이 들었다.\n",
            "\n",
            "Movie Sunny fine-tuning\n",
            "greedy True:  인간 임 나미. 너는 임 나미? (장미에게) 나 조퇴 좀 하게....말투가 전라도 말투다.\n",
            "greedy False:  인간 임 나미. 너 클때는 응? 다 멋있다. 이런 모습 처음이네. 응? 진희는? 황홀경\n",
            "\n",
            "Novel fine-tuning\n",
            "greedy True:  인간에게 있어서 가장 큰 고비는 무엇인가가 아닐까.\n",
            "greedy False:  인간으로서 열등감 같은 것을 느끼기는 커녕, 아침 일찍 일어나기 위해 슬근슬근 논다느니보다 오히려 근심과 걱정이 앞선다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-WP5lfybliI",
        "outputId": "1b64a46e-7259-49c0-9ef8-240cb1306d44"
      },
      "source": [
        "하지만 gpt_fine_tuning_test('그녀', p=0.95)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPT-2\n",
            "greedy True:  그녀와 함께 있으면 행복할 것 같다.\n",
            "greedy False:  그녀 손목이!\n",
            "\n",
            "EXO lyrics fine-tuning\n",
            "greedy True:  그녀 곁에서 모두 다 물러나 이젠 조금씩 사나워진다.\n",
            "greedy False:  그녀 앞에 손짓 발짓 저벅저벅 빛나는 검은 그림자 그림자.\n",
            "\n",
            "Movie Sunny fine-tuning\n",
            "greedy True:  그녀들, 일제히 수지를 쳐다본다.                                                                                            \n",
            "greedy False:  그녀들을 보자 웃음바다가 된 공터. 언제 눈물바다가 됐냐는 듯 바라보는 나미. 진희 금옥 황 진희 금옥 축하한다.\n",
            "\n",
            "Novel fine-tuning\n",
            "greedy True:  그녀에게는 그 어떤 시련도 없었다.\n",
            "greedy False:  그녀에게는 돈 몇 푼도 벌지 못하지만 그것으로 그녀는 제법 버석고 기름진 대지를 빨아들이고 가뿐하였다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F3l3ryscXrj",
        "outputId": "f00f8959-ff73-479d-c174-6fa634a9bc09"
      },
      "source": [
        "gpt_fine_tuning_test('너는', p=0.95)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPT-2\n",
            "greedy True:  너는 내 운명\n",
            "greedy False:  너는 그 사람이 원하는 사람인데요\n",
            "\n",
            "EXO lyrics fine-tuning\n",
            "greedy True:  너는 날 미치게 만드는구나\n",
            "greedy False:  너는 나 뿐 아니라 동경과 부러움의 대상이었지\n",
            "\n",
            "Movie Sunny fine-tuning\n",
            "greedy True:  너는 남 걱정 하지 말고 이거(동작 흉내) 턴 할때 팍팍 좀 돌란 말이야. (동작 흉내) 팍팍 좀 돌란 말이야.\n",
            "greedy False:  너는? 황 진희랑 사귄다며? 나 보고 황 진희래.. 너 이 씨발년아. 니가 좀 맞아.\n",
            "\n",
            "Novel fine-tuning\n",
            "greedy True:  너는 나를 어떻게 생각하는지, 내가 왜 나를 미워해야 하는지, 내가 왜 남을 미워해야 하는지, 왜 남을 미워해야 하는지, 왜 남을 미워해야 하는지, 왜 남을 미워해야 하는지, 왜 남을 미워해야 하는지, 왜 남을 미워해야 하는지, 왜 남을 미워해야 하는지, 왜 남을 미워해야 하는지, 왜 남을 미워해야 하는지, 왜 남을 미워해야 하는지, 왜 남을 미워해야 하는지, 왜 남을 미워해야 하는지, 왜 남을\n",
            "greedy False:  너는 어제의 내일이 두렵지 않은가!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhJGcPI_cZBo",
        "outputId": "81c57d75-455d-452e-da87-6e7e4ecb881b"
      },
      "source": [
        "gpt_fine_tuning_test('나는', p=0.95)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPT-2\n",
            "greedy True:  나는 이 모든 것을 알고 있다.\n",
            "greedy False:  나는 노동조합이 파업으로 인한 고용불안 등을 사유화하지 못하도록 노조활동이 원칙대로 완수될 수 있도록 노력할 것이다.\n",
            "\n",
            "EXO lyrics fine-tuning\n",
            "greedy True:  나는 너를 사랑한 것이 아니라 널 사랑한 것이다\n",
            "greedy False:  나는 여기서 멈추지 않고, 다시 나에게로 돌진하지 않을 수 없다.\n",
            "\n",
            "Movie Sunny fine-tuning\n",
            "greedy True:  나는 너를 안다는 듯 묘한 미소를 띄며 노래를 흥얼거리는 춘화. 살짝 떨리는 손. 살짝 떨리는 손. 살짝 떨리는 손. 살짝 떨리는 손.\n",
            "greedy False:  나는 괜찮다니깐. (시위대 보며) 누가 뭐래? 폭력 시위나 하자고. (시위대 보며) 지금 이 시간부터 총동원해 완전 초토화 합니다.\n",
            "\n",
            "Novel fine-tuning\n",
            "greedy True:  나는 그 여학생에게 반항 한번 못해 본 것 같다.\n",
            "greedy False:  나는 니가 자기를 좋아하든 말든 욕을 먹어도 내색조차 못하는데...... 무슨 병인가.”\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTJpEdfDdAwH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}